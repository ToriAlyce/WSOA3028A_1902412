<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Charlette's Website</title>
    <link rel="stylesheet" href="../CSS/main.css" />
    <script type="module" src="../Java_Script/menu.js"></script>

    <style>
        .menu {
            text-align: center;
            font-weight: bold;
            font-size: 25px;
            line-height: 21pt;
            font-family: Georgia, 'Times New Roman', Times, serif, cursive;
            background-color:  rgb(241, 210, 219);
        }
    </style>
</head>
 <body>
    <main>
        <h1>Charlette's Web<span class="emphasize">site</span></h1>
        <nav class="menu"></nav>
        <h2>#14th Blog</h2>
        <h3>Radical AI Podcast</h3>
        <section>
            <p>
                Recently we got to listen to a Podcast called ‘The Radical AI Podcast: Love, Challenge, and Hope: Building a Movement 
                to Dismantle the New Jim Code’[2] were a lot of very interesting topics where discussed. The topics were in terms of 
                how racism is imbedded in technology and discriminatory design and what we can do to try to prevent these issues before 
                they even start. 
            </p>
            <p>
                The topic on discriminatory design I found the most fascinating. Here they discussed how an unintentional race issue 
                can be brought about within design, and how we need to create more awareness within the design world as to not discriminate, 
                exclude, or be biased towards people even if it is not necessarily intentional.  In terms of unintentional discriminatory 
                design, the designer of a technology doesn’t have to want to design something that can harm people, but, due to the way 
                things are designed, some unintentional problems can arise. It was discussed that even if a program was created on a race 
                neutral basis that it can still lead to various issues as it does not take into account all the different aspects of 
                cultures that we already know, and then leads to creating its own biases.
                <blockquote>
                    “Having a race neutral algorithm or AI system can be very deadly.”[2] 
                </blockquote>
                However, if we implement all our knowledge into the AI it can still be problematic. Machines will then begin to learn 
                from our own biases that have been ingrained into our society. 
                <blockquote>
                    “When the data we feed the machines reflects the history of our own unequal society, we are, in effect, 
                    asking the program to learn our own biases.”[1] 
                </blockquote>
                In essence, we first have to unlearn all aspects of discrimination or racism that have been imbedded into our society 
                before we then use the technology to help against these issues. 
            </p>
            <p>
                This then brings up the idea that most designers hate to admit to: the idea that technology should not be involved 
                in almost every aspects of life and that it could be more beneficial to look at situations from a more human perspective, 
                than relying on a machine to decide someone’s fate. Machines are designed to process information that they have been given, 
                and in many cases that information is tainted and flawed. 
                <blockquote>
                    “It means that programs are not magic. If you give them flawed information, they won’t fix the flaws, they just process 
                    the information.”[1]
                </blockquote>
                Thus, bringing into question if technology is really necessary to be implemented into all aspects of life, 
                as there are things only humans can understand that machines cannot.
            </p>
            <p>
                There are many ways that this discrimination can be created: one aspect discussed was the design created to help deploy 
                policemen into the higher crime rated areas. The design worked off already processed information on crime cases, therefore 
                some areas that had more reported cases had more policemen deployed to that area. The problematic aspects of this kind 
                of design was that since there where more policemen in that area more crimes got reported and the technology began sending 
                even more cops to that area, and therefore other areas were neglected. Hence, when designing technology, we need to be able 
                to take all aspects and situations into consideration not just working off the bottom line of things. 
            </p>
            <p>
                However, the need to still create and design technology can be very beneficial to our society, and with these very 
                important red flags being risen, this topic needs to be more thoroughly discussed. 
                <blockquote>
                    “But, while some of the most prominent voices in the industry are concerned with the far-off future apocalyptic 
                    potential of AI, there is less attention paid to the more immediate problem of how we prevent these programs from 
                    amplifying the inequalities of our past and affecting the most vulnerable members of our society.” [1]
                </blockquote>
                One of the aspects mentioned was how our pedagogy system can be used to bring this topic into light. There are thousands 
                of students all around the world that are learning to become the future creators of design and technology, and this topic 
                is something that they really need to be made aware of. By implementing the topic of flawed discriminatory design into 
                their education, the students of future design will be made aware of this problematic aspect of technology and will then 
                be able to either come up with a solution to fix these aspects, or at least be able to be more aware of how their designs 
                may be flawed. 
            </p>
            <p>
                In conclusion, the topic of unintentional racism has been discussed and it is very necessary for it to be discussed further 
            throughout the design world. Listening to this podcast I feel it was a very necessary topic and is something that I, as a 
            designer and designers all across the world, need to be made aware of. The more that people acknowledge these kind of issues, 
            the more we can do to stop discriminatory design and find ways to create technology that isn’t biased, and can benefit all 
            kinds of people all around the world.
            </p> 
                <blockquote>
                    <h3>References:</h3>
                    [1] Rise of the racist robots – how AI is learning all our worst impulses. (2020). Retrieved 28 June 2020, from 
                    https://www.theguardian.com/inequality/2017/aug/08/rise-of-the-racist-robots-how-ai-is-learning-all-our-worst-impulses
                </br>
                    [2] The Radical AI Podcast (2020) ‘LOVE, CHALLENGE, AND HOPE: BUILDING A MOVEMENT TO DISMANTLE THE NEW JIM CODE WITH 
                    RUHA BENJAMIN’. (The Radical AI Podcast). Available at: https://podcasts.apple.com/us/podcast/love-challenge-hope-
                    building-movement-to-dismantle/id1505229145?i=1000473742475 (Accessed: 28 June 2020).
                </blockquote>
            </p>
        </section>
    </main>
    <blockquote>
        <nav>
            <a href="Designer_Post_13.html">Back -</a>
            <a href="Designer_Post_15.html">Next</a>
         </nav>
    </blockquote>
 </body>
</html>